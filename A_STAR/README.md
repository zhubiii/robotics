# My work
## Video
https://youtu.be/VHNDjXfwkso  

## Part 2
I have decided to talk about the digit delivery humanoid robot by Ford, shared by Melody Su(Yuhan). Right off the bat you can see a very exposed lidar on top of the robots head. This gives a scan of the enviorment and likely allows the robot to see and map out its surroundings. The LIDAR probably scans everything from the car to the door (its destination). We saw with the lidar example used on campus sqaure, that the range is pretty good and atleast to a human eye, many objects could be detected such as trash cans, tables, and brick walls. Given the decent range of the LIDAR, and the fact that the delivery car in the video pulls up very close to the house, my guess is that when the robot initially gets out of the car it will scan all around using something akin to SLAM to map its surroundings. The car is probably a prominent landmark that the algorithm can use to localize the robot so that it always knows where it is in relation to the car. Then, with the use of computer vision machine learning, it can probably detect where the front door is from previous data. At this point it has mapped out its destination, it knows its starting point, and it has detected the nearby enviorment. With this information all you need is a global plan. I would guess that they use A* to map out a goal. This is because the robot clearly avoids the scooter laying down which I would guess it detected from its original lidar scans. A* then finds the shortest path around it to the door. In terms of control, it definitely has a lot more degrees of freedom than our 2d robot had so its hard to say what all the controls are. Perhaps some machine learning and a gyroscope allows it to stay upright while the fine motors that control the leg are what the feedback control is controlling. The video only gives a short snippet of it actually working so there is not a lot of correction seen or any indication of poorly set gains for whatever controller they are using. (probably because of what the boston dynamics guy said, for every success video theres a million fails). Some scenrios I could see this not working well is if the driveway is blocked and it cannot get close enough to the house originally to scan the door. Or, since this thing looks pretty futuristic, if in the future people had glass houses and glass scooters then the lidar would not be able to effectively detect it.

## Citations
I used this matlab tutorial https://www.mathworks.com/matlabcentral/fileexchange/26248-a-a-star-search-for-path-planning-tutorial for the sole reason of seeing how to implement a nice user input interface. I did NOT use/look at any of the actual matlab implementation of the algorithm. The code I directly referenced is in a matlab file called reference.m  
  
I also watched a few videos from Sebastian League, a youtuber who makes video games. He has a great visualization/explanation of A* https://youtu.be/-L-WgKMFuhE
